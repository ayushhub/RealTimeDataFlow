https://github.com/ayushhub/RealTimeDataFlow/blob/master/Dashboard.png

ADD JAR /usr/hdp/2.5.0.0-1245/hive2/lib/json-serde-1.3.8-SNAPSHOT-jar-with-dependencies.jar;
create table IF NOT EXISTS tweets_sentiment stored as orc as select
  tweet_id,
  case
    when sum( polarity ) > 0 then 'positive'
    when sum( polarity ) < 0 then 'negative'  
    else 'neutral' end as sentiment
from l3 group by tweet_id;


hadoop fs -ls /tmp/tweets_staging | awk '{print $8}' | while read f; do hadoop fs -cat $f | grep escravadaonedir >/tmp/null && echo $f; done


SELECT * FROM tweets_clean LIMIT 10;

tweet_id":838029076367568897
displayname":"escravadaonedir
ANALYZING SOCIAL MEDIA AND CUSTOMER SENTIMENT




grep -rnw '/tmp/tweets' -e "838029076367568897"


https://hortonworks.com/hadoop-tutorial/how-to-refine-and-visualize-sentiment-data/#creating-a-data-flow-with-nifi

Access Virtual Machine
http://127.0.0.1:8080/#/main/dashboard/metrics
raj_ops/raj_ops
make sure setup kafka topics delete to true
Access Terminal (2 windows)
ssh root@sandbox.hortonworks.com -p 2222
Winter2000

scp -P 2222 <filename> root@127.0.0.1:/root/.

http://www.jsoneditoronline.org

select tweet_id,
  case
    when sum( polarity ) > 0 then 'positive'
    when sum( polarity ) < 0 then 'negative'  
    else 'neutral' end as sentiment
from l3 
where time_zone != ‘Tokyo’
group by tweet_id limit 100;

Start Nifi
cd /root/HDF-1.2.0.1-1/nifi/bin
sudo service nifi start
sudo service nifi stop
Access Nifi
http://127.0.0.1:8090/nifi/
finale
Check Data
cd /root/nifi_output
hadoop fs –ls /groupm
hive
show databases;
show tables;
select * from truck_events1;
/usr/hdp/current/kafka-broker/bin/kafka-console-consumer.sh --zookeeper sandbox.hortonworks.com:2181 --topic truck_events2
Elasticsearch
cd /home
sudo su – elastic
cd /opt/elasticsearch-2.4.0
bin/elasticsearch
curl -XGET 127.0.0.1:9200
curl -XGET 127.0.0.1:9200/twitter/_search?pretty

curl -XDELETE localhost:9200/shop

curl -XDELETE 127.0.0.1:9200/twitter

curl -XPUT 'localhost:9200/twitter?pretty' -H 'Content-Type: application/json' -d'
{
    "settings" : {
        "number_of_shards" : 3,
        "number_of_replicas" : 2
    }
}
'



Kibana
https://community.hortonworks.com/articles/56648/creating-a-kibana-dashboard-of-twitter-data-pushed.html
cd /opt/kibana-4.6.1-linux-x86_64
bin/kibana

Nifi
Open new window
Start gettwitterinelasticsearch
twitter
Consumer Secret: eAGE5zXj0heBFgI3eZLVXgQoVrDakKyWGAOIfEdkkETv808RmY
Access Token Secret: ixd1gEZJ6ZafmMZEFsdzfXbndzGEKlBhP5C3buEYzR0av
Zepplin
http://sandbox.hortonworks.com:9995/#/
%sh
hadoop fs -ls

%elasticsearch
count /twitter/default

%elasticsearch
search /twitter/default {“aggs” : {“language” : {“terms” : {“field” : “lang” } } } }

%elasticsearch
search /twitter/default {"aggs" : {"geo_enabled" : {"terms" : {"field" : "user.geo_enabled" } } } }

%elasticsearch
search /twitter/default {"aggs" : {    "distinct_users" : {        "terms" : {            "field" : "user.screen_name"                     } } } }

%elasticsearch
size ${limit=10}
search /twitter/default { "query": { "match_all": { } }












Kafka
/usr/hdp/current/kafka-broker/bin/kafka-topics.sh --delete --zookeeper sandbox.hortonworks.com:2181 --topic truck_events
/usr/hdp/current/kafka-broker/bin/kafka-topics.sh --create --zookeeper sandbox.hortonworks.com:2181 --replication-factor 1 --partitions 2 --topic sfo-demo
/usr/hdp/current/kafka-broker/bin/kafka-topics.sh --list --zookeeper sandbox.hortonworks.com:2181
/usr/hdp/current/kafka-broker/bin/kafka-console-consumer.sh --zookeeper sandbox.hortonworks.com:2181 --topic sfo-demo
Storm
/root/iot-truck-streaming
config.properties
/usr/maven/bin/mvn clean package -DskipTests
cd ~/iot-truck-streaming
storm jar storm-streaming/target/storm-streaming-1.0-SNAPSHOT.jar com.hortonworks.streaming.impl.topologies.TruckEventKafkaExperimTopology /etc/storm_demo/config.properties
Hive
CREATE EXTERNAL TABLE IF NOT EXISTS truck_events1(        time STRING,         Miles_per_Gallon INT,        Cylinders INT,        Name STRING,        totalmileage INT,         destination STRING,        ride STRING,        locationx STRING,        locationy STRING,        origin STRING)    COMMENT 'truck events'    ROW FORMAT DELIMITED    FIELDS TERMINATED BY '|'    STORED AS TEXTFILE    location '/groupm';
Pig
A = LOAD 'default.truck_events1' USING org.apache.hcatalog.pig.HCatLoader();
B = filter A by miles_per_gallon == 55;
STORE B INTO ‘default.pig_events’ USING org.apache.hcatalog.pig.HCatLoader();

Zepplin
http://sandbox.hortonworks.com:9995/#/

%elasticsearch
count /twitter/default

%elasticsearch
search /twitter/default {“aggs” : {“language” : {“terms” : {“field” : “lang” } } } }

%elasticsearch
search /twitter/default {"aggs" : {"geo_enabled" : {"terms" : {"field" : "user.geo_enabled" } } } }

%elasticsearch
search /twitter/default {"aggs" : {    "distinct_users" : {        "terms" : {            "field" : "user.screen_name"                     } } } }

HBase
su hbase
hbase shell
create 'driver_events', 'allevents'    
create 'driver_dangerous_events', 'events'
create 'driver_dangerous_events_count', 'counters'
list    
exit
hbase shell

list
count 'driver_events'
count 'driver_dangerous_events'
count 'driver_dangerous_events_count'    
exit
Display in correct format
scan 'driver_dangerous_events_count' , {COLUMNS => ['counters:driverId:toInt', 'counters:incidentTotalCount:toLong']}
AWS
URL

APPENDIX

Install Nifi
https://hortonworks.com/hadoop-tutorial/realtime-event-processing-nifi-kafka-storm/
https://community.hortonworks.com/articles/44060/quickly-adding-hdf-to-hdp-25-sandbox.html
Hadoop Configuration
/etc/hadoop/conf
core-site.xml – Cluster wide setting (distributed to all nodes)
hdfs-site.xml – Cluster & Data node specific
yarn-site.xml – Resource Manager (scheduler)
Administrator
hadoop fsck / (File system check)
hadoop fs –du –s –h / (Free Storage)
hadoop fs –count –q / (quota info)
hadoop fsck –blocks –locations / (DN and block of files INFO)
yarn application –list
yarn application –kill
hadoop queue –list
Kafka
go to /usr/hdp/current/kafka-broker

Manually delete
go to /tmp/kafka-logs
sudo ./zookeeper-shell.sh localhost:2181 rmr /brokers/topics/your_topic
Elasticsearch
	•	https://community.hortonworks.com/articles/54755/enabling-the-zeppelin-elasticsearch-interpreter.html
	•	https://community.hortonworks.com/articles/56121/how-to-pull-data-from-twitter-and-push-data-to-ela.html
	•	https://community.hortonworks.com/articles/56121/how-to-pull-data-from-twitter-and-push-data-to-ela.html





${twitter.msg:isEmpty():not()}

${twitter.text:isEmpty():not():and(${twitter.lang:equals("en")})}

/root/jars/hadoop-lzo-0.4.21-SNAPSHOT.jar
