<?xml version="1.0" encoding="UTF-8" standalone="yes"?><template><description></description><name>finale</name><snippet><connections><id>0adce99a-5b1a-4199-a403-93b7f9732419</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>0df58d16-7d9b-4aa1-8832-bb0632857214</groupId><id>dacc95ee-23f0-4c5e-ac74-4232c8ebde42</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>0df58d16-7d9b-4aa1-8832-bb0632857214</groupId><id>72b20cad-d032-4527-9380-b51f906fdeaf</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>370ed702-ad82-430c-a8da-2171930a5c88</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>0df58d16-7d9b-4aa1-8832-bb0632857214</groupId><id>add1e6b5-df32-4b11-8e38-3bea26c88c78</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>merged</selectedRelationships><source><groupId>0df58d16-7d9b-4aa1-8832-bb0632857214</groupId><id>e9dd9706-19f8-4e43-8c0b-5961ef72626f</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>6143eaaa-c329-4d22-b123-c6fefa31c4f9</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>0df58d16-7d9b-4aa1-8832-bb0632857214</groupId><id>d9bb0c9f-e32b-4f57-8c2f-676e09aacbe4</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>merged</selectedRelationships><source><groupId>0df58d16-7d9b-4aa1-8832-bb0632857214</groupId><id>e9dd9706-19f8-4e43-8c0b-5961ef72626f</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>b2ada273-78c1-431a-90b5-979f2fce4f25</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>0df58d16-7d9b-4aa1-8832-bb0632857214</groupId><id>acca1884-bb32-45c8-a20a-4bba8630250d</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>merged</selectedRelationships><source><groupId>0df58d16-7d9b-4aa1-8832-bb0632857214</groupId><id>e9dd9706-19f8-4e43-8c0b-5961ef72626f</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>80fa707c-b82d-4284-879a-6c40ae799fb6</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>0df58d16-7d9b-4aa1-8832-bb0632857214</groupId><id>3a358c2b-5348-4aa3-95e1-3f805e589f4a</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>merged</selectedRelationships><source><groupId>0df58d16-7d9b-4aa1-8832-bb0632857214</groupId><id>e9dd9706-19f8-4e43-8c0b-5961ef72626f</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>7c009366-4dca-405c-8ede-d0218bde17ea</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>0df58d16-7d9b-4aa1-8832-bb0632857214</groupId><id>2eedcd56-aa0a-4064-94f9-8acc48068c91</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name>MergeContent(logs)</name><selectedRelationships>unmatched</selectedRelationships><source><groupId>0df58d16-7d9b-4aa1-8832-bb0632857214</groupId><id>de1b9195-a809-4aef-abc2-862de896d217</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>936ca53e-8f5d-4be6-a505-72aa69460cd5</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>0df58d16-7d9b-4aa1-8832-bb0632857214</groupId><id>de1b9195-a809-4aef-abc2-862de896d217</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>0df58d16-7d9b-4aa1-8832-bb0632857214</groupId><id>ee4e7849-a123-4958-a297-6062b9818978</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>4a69424d-4eca-4c05-b49f-fd0b35a3e169</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>0df58d16-7d9b-4aa1-8832-bb0632857214</groupId><id>ee4e7849-a123-4958-a297-6062b9818978</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>splits</selectedRelationships><source><groupId>0df58d16-7d9b-4aa1-8832-bb0632857214</groupId><id>dacc95ee-23f0-4c5e-ac74-4232c8ebde42</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>b94b6f2d-4c65-4675-82c3-870199f3d7bc</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>0df58d16-7d9b-4aa1-8832-bb0632857214</groupId><id>e9dd9706-19f8-4e43-8c0b-5961ef72626f</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>search_for_truck_event_data</selectedRelationships><source><groupId>0df58d16-7d9b-4aa1-8832-bb0632857214</groupId><id>de1b9195-a809-4aef-abc2-862de896d217</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>359fe023-acd8-40ca-9700-2b7e498bd3d0</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>0df58d16-7d9b-4aa1-8832-bb0632857214</groupId><id>c593912d-ceeb-4bce-b16c-8d9af0bf9cb3</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>merged</selectedRelationships><source><groupId>0df58d16-7d9b-4aa1-8832-bb0632857214</groupId><id>2eedcd56-aa0a-4064-94f9-8acc48068c91</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><processors><id>2eedcd56-aa0a-4064-94f9-8acc48068c91</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><position><x>1473.979240349775</x><y>239.92553236154288</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Keep Path</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>If using the Zip or Tar Merge Format, specifies whether or not the FlowFiles' paths should be included in their entry names; if using other merge strategy, this value is ignored</description><displayName>Keep Path</displayName><dynamic>false</dynamic><name>Keep Path</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum Group Size</key><value><description>The maximum size for the bundle. If not specified, there is no maximum.</description><displayName>Maximum Group Size</displayName><dynamic>false</dynamic><name>Maximum Group Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Merge Strategy</key><value><allowableValues><description>Generates 'bins' of FlowFiles and fills each bin as full as possible. FlowFiles are placed into a bin based on their size and optionally their attributes (if the &lt;Correlation Attribute&gt; property is set)</description><displayName>Bin-Packing Algorithm</displayName><value>Bin-Packing Algorithm</value></allowableValues><allowableValues><description>Combines fragments that are associated by attributes back into a single cohesive FlowFile. If using this strategy, all FlowFiles must have the attributes &lt;fragment.identifier&gt;, &lt;fragment.count&gt;, and &lt;fragment.index&gt; or alternatively (for backward compatibility purposes) &lt;segment.identifier&gt;, &lt;segment.count&gt;, and &lt;segment.index&gt;. All FlowFiles with the same value for &quot;fragment.identifier&quot; will be grouped together. All FlowFiles in this group must have the same value for the &quot;fragment.count&quot; attribute. All FlowFiles in this group must have a unique value for the &quot;fragment.index&quot; attribute between 0 and the value of the &quot;fragment.count&quot; attribute.</description><displayName>Defragment</displayName><value>Defragment</value></allowableValues><defaultValue>Bin-Packing Algorithm</defaultValue><description>Specifies the algorithm used to merge content. The 'Defragment' algorithm combines fragments that are associated by attributes back into a single cohesive FlowFile. The 'Bin-Packing Algorithm' generates a FlowFile populated by arbitrarily chosen FlowFiles</description><displayName>Merge Strategy</displayName><dynamic>false</dynamic><name>Merge Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Attribute Strategy</key><value><allowableValues><displayName>Keep Only Common Attributes</displayName><value>Keep Only Common Attributes</value></allowableValues><allowableValues><displayName>Keep All Unique Attributes</displayName><value>Keep All Unique Attributes</value></allowableValues><defaultValue>Keep Only Common Attributes</defaultValue><description>Determines which FlowFile attributes should be added to the bundle. If 'Keep All Unique Attributes' is selected, any attribute on any FlowFile that gets bundled will be kept unless its value conflicts with the value from another FlowFile. If 'Keep Only Common Attributes' is selected, only the attributes that exist on all FlowFiles in the bundle, with the same value, will be preserved.</description><displayName>Attribute Strategy</displayName><dynamic>false</dynamic><name>Attribute Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Compression Level</key><value><allowableValues><displayName>0</displayName><value>0</value></allowableValues><allowableValues><displayName>1</displayName><value>1</value></allowableValues><allowableValues><displayName>2</displayName><value>2</value></allowableValues><allowableValues><displayName>3</displayName><value>3</value></allowableValues><allowableValues><displayName>4</displayName><value>4</value></allowableValues><allowableValues><displayName>5</displayName><value>5</value></allowableValues><allowableValues><displayName>6</displayName><value>6</value></allowableValues><allowableValues><displayName>7</displayName><value>7</value></allowableValues><allowableValues><displayName>8</displayName><value>8</value></allowableValues><allowableValues><displayName>9</displayName><value>9</value></allowableValues><defaultValue>1</defaultValue><description>Specifies the compression level to use when using the Zip Merge Format; if not using the Zip Merge Format, this value is ignored</description><displayName>Compression Level</displayName><dynamic>false</dynamic><name>Compression Level</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum Number of Entries</key><value><description>The maximum number of files to include in a bundle. If not specified, there is no maximum.</description><displayName>Maximum Number of Entries</displayName><dynamic>false</dynamic><name>Maximum Number of Entries</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Minimum Group Size</key><value><defaultValue>0 B</defaultValue><description>The minimum size of for the bundle</description><displayName>Minimum Group Size</displayName><dynamic>false</dynamic><name>Minimum Group Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum number of Bins</key><value><defaultValue>100</defaultValue><description>Specifies the maximum number of bins that can be held in memory at any one time</description><displayName>Maximum number of Bins</displayName><dynamic>false</dynamic><name>Maximum number of Bins</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Delimiter Strategy</key><value><allowableValues><description>The values of Header, Footer, and Demarcator will be retrieved from the contents of a file</description><displayName>Filename</displayName><value>Filename</value></allowableValues><allowableValues><description>The values of Header, Footer, and Demarcator will be specified as property values</description><displayName>Text</displayName><value>Text</value></allowableValues><defaultValue>Filename</defaultValue><description>Determines if Header, Footer, and Demarcator should point to files containing the respective content, or if the values of the properties should be used as the content.</description><displayName>Delimiter Strategy</displayName><dynamic>false</dynamic><name>Delimiter Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Merge Format</key><value><allowableValues><description>A bin of FlowFiles will be combined into a single TAR file. The FlowFiles' &lt;path&gt; attribute will be used to create a directory in the TAR file if the &lt;Keep Paths&gt; property is set to true; otherwise, all FlowFiles will be added at the root of the TAR file. If a FlowFile has an attribute named &lt;tar.permissions&gt; that is 3 characters, each between 0-7, that attribute will be used as the TAR entry's 'mode'.</description><displayName>TAR</displayName><value>TAR</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single ZIP file. The FlowFiles' &lt;path&gt; attribute will be used to create a directory in the ZIP file if the &lt;Keep Paths&gt; property is set to true; otherwise, all FlowFiles will be added at the root of the ZIP file. The &lt;Compression Level&gt; property indicates the ZIP compression to use.</description><displayName>ZIP</displayName><value>ZIP</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 3 FlowFile Stream</description><displayName>FlowFile Stream, v3</displayName><value>FlowFile Stream, v3</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 2 FlowFile Stream</description><displayName>FlowFile Stream, v2</displayName><value>FlowFile Stream, v2</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 1 FlowFile Package</description><displayName>FlowFile Tar, v1</displayName><value>FlowFile Tar, v1</value></allowableValues><allowableValues><description>The contents of all FlowFiles will be concatenated together into a single FlowFile</description><displayName>Binary Concatenation</displayName><value>Binary Concatenation</value></allowableValues><allowableValues><description>The Avro contents of all FlowFiles will be concatenated together into a single FlowFile</description><displayName>Avro</displayName><value>Avro</value></allowableValues><defaultValue>Binary Concatenation</defaultValue><description>Determines the format that will be used to merge the content.</description><displayName>Merge Format</displayName><dynamic>false</dynamic><name>Merge Format</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Footer File</key><value><description>Filename specifying the footer to use. If not specified, no footer is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Footer</displayName><dynamic>false</dynamic><name>Footer File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Bin Age</key><value><description>The maximum age of a Bin that will trigger a Bin to be complete. Expected format is &lt;duration&gt; &lt;time unit&gt; where &lt;duration&gt; is a positive integer and time unit is one of seconds, minutes, hours</description><displayName>Max Bin Age</displayName><dynamic>false</dynamic><name>Max Bin Age</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Demarcator File</key><value><description>Filename specifying the demarcator to use. If not specified, no demarcator is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Demarcator</displayName><dynamic>false</dynamic><name>Demarcator File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Correlation Attribute Name</key><value><description>If specified, like FlowFiles will be binned together, where 'like FlowFiles' means FlowFiles that have the same value for this Attribute. If not specified, FlowFiles are bundled by the order in which they are pulled from the queue.</description><displayName>Correlation Attribute Name</displayName><dynamic>false</dynamic><name>Correlation Attribute Name</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Header File</key><value><description>Filename specifying the header to use. If not specified, no header is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Header</displayName><dynamic>false</dynamic><name>Header File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Minimum Number of Entries</key><value><defaultValue>1</defaultValue><description>The minimum number of files to include in a bundle</description><displayName>Minimum Number of Entries</displayName><dynamic>false</dynamic><name>Minimum Number of Entries</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Keep Path</key><value>false</value></entry><entry><key>Maximum Group Size</key></entry><entry><key>Merge Strategy</key><value>Bin-Packing Algorithm</value></entry><entry><key>Attribute Strategy</key><value>Keep Only Common Attributes</value></entry><entry><key>Compression Level</key><value>1</value></entry><entry><key>Maximum Number of Entries</key><value>70</value></entry><entry><key>Minimum Group Size</key><value>0 B</value></entry><entry><key>Maximum number of Bins</key><value>100</value></entry><entry><key>Delimiter Strategy</key><value>Filename</value></entry><entry><key>Merge Format</key><value>Binary Concatenation</value></entry><entry><key>Footer File</key></entry><entry><key>Max Bin Age</key></entry><entry><key>Demarcator File</key></entry><entry><key>Correlation Attribute Name</key></entry><entry><key>Header File</key></entry><entry><key>Minimum Number of Entries</key><value>50</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>MergeContent(logs)</name><relationships><autoTerminate>true</autoTerminate><description>If the bundle cannot be created, all FlowFiles that would have been used to created the bundle will be transferred to failure</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>The FlowFile containing the merged content</description><name>merged</name></relationships><relationships><autoTerminate>true</autoTerminate><description>The FlowFiles that were used to create the bundle</description><name>original</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.MergeContent</type></processors><processors><id>add1e6b5-df32-4b11-8e38-3bea26c88c78</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><position><x>915.283911427499</x><y>415.2024819564773</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Group</key><value><description>Sets the group on the output file to the value of this attribute.  You may also use expression language such as ${file.group}.</description><displayName>Group</displayName><dynamic>false</dynamic><name>Group</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Owner</key><value><description>Sets the owner on the output file to the value of this attribute.  You may also use expression language such as ${file.owner}.</description><displayName>Owner</displayName><dynamic>false</dynamic><name>Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Create Missing Directories</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>true</defaultValue><description>If true, then missing destination directories will be created. If false, flowfiles are penalized and sent to failure.</description><displayName>Create Missing Directories</displayName><dynamic>false</dynamic><name>Create Missing Directories</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Permissions</key><value><description>Sets the permissions on the output file to the value of this attribute.  Format must be either UNIX rwxrwxrwx with a - in place of denied permissions (e.g. rw-r--r--) or an octal number (e.g. 644).  You may also use expression language such as ${file.permissions}.</description><displayName>Permissions</displayName><dynamic>false</dynamic><name>Permissions</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Maximum File Count</key><value><description>Specifies the maximum number of files that can exist in the output directory</description><displayName>Maximum File Count</displayName><dynamic>false</dynamic><name>Maximum File Count</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Last Modified Time</key><value><description>Sets the lastModifiedTime on the output file to the value of this attribute.  Format must be yyyy-MM-dd'T'HH:mm:ssZ.  You may also use expression language such as ${file.lastModifiedTime}.</description><displayName>Last Modified Time</displayName><dynamic>false</dynamic><name>Last Modified Time</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Directory</key><value><description>The directory to which files should be written. You may use expression language such as /aa/bb/${path}</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Group</key></entry><entry><key>Owner</key></entry><entry><key>Create Missing Directories</key><value>true</value></entry><entry><key>Permissions</key></entry><entry><key>Maximum File Count</key></entry><entry><key>Last Modified Time</key></entry><entry><key>Directory</key><value>/root/nifi_output/truck_events</value></entry><entry><key>Conflict Resolution Strategy</key><value>fail</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>PutFile(truck_events)</name><relationships><autoTerminate>true</autoTerminate><description>Files that could not be written to the output directory for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to the output directory are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.PutFile</type></processors><processors><id>d9bb0c9f-e32b-4f57-8c2f-676e09aacbe4</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><position><x>1505.278871704651</x><y>423.0273654105257</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Partition</key><value><description>Specifies which Kafka Partition to add the message to. If using a message delimiter, all messages in the same FlowFile will be sent to the same partition. If a partition is specified but is not valid, then all messages within the same FlowFile will use the same partition but it remains undefined which partition is used.</description><displayName>Partition</displayName><dynamic>false</dynamic><name>Partition</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Record Size</key><value><defaultValue>1 MB</defaultValue><description>The maximum size that any individual record can be.</description><displayName>Max Record Size</displayName><dynamic>false</dynamic><name>Max Record Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Client Name</key><value><description>Client Name to use when communicating with Kafka</description><displayName>Client Name</displayName><dynamic>false</dynamic><name>Client Name</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Compression Codec</key><value><allowableValues><description>Compression will not be used for any topic.</description><displayName>None</displayName><value>none</value></allowableValues><allowableValues><description>Compress messages using GZIP</description><displayName>GZIP</displayName><value>gzip</value></allowableValues><allowableValues><description>Compress messages using Snappy</description><displayName>Snappy</displayName><value>snappy</value></allowableValues><defaultValue>none</defaultValue><description>This parameter allows you to specify the compression codec for all data generated by this producer.</description><displayName>Compression Codec</displayName><dynamic>false</dynamic><name>Compression Codec</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Message Delimiter</key><value><description>Specifies the delimiter (interpreted in its UTF-8 byte representation) to use for splitting apart multiple messages within a single FlowFile. If not specified, the entire content of the FlowFile will be used as a single message. If specified, the contents of the FlowFile will be split on this delimiter and each section sent as a separate Kafka message. Note that if messages are delimited and some messages for a given FlowFile are transferred successfully while others are not, the messages will be split into individual FlowFiles, such that those messages that were successfully sent are routed to the 'success' relationship while other messages are sent to the 'failure' relationship.</description><displayName>Message Delimiter</displayName><dynamic>false</dynamic><name>Message Delimiter</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition Strategy</key><value><allowableValues><description>Messages will be assigned partitions in a round-robin fashion, sending the first message to Partition 1, the next Partition to Partition 2, and so on, wrapping as necessary.</description><displayName>Round Robin</displayName><value>Round Robin</value></allowableValues><allowableValues><description>Messages will be assigned to random partitions.</description><displayName>Random</displayName><value>Random Robin</value></allowableValues><allowableValues><description>The &lt;Partition&gt; property will be used to determine the partition. All messages within the same FlowFile will be assigned to the same partition.</description><displayName>User-Defined</displayName><value>User-Defined</value></allowableValues><defaultValue>Round Robin</defaultValue><description>Specifies how messages should be partitioned when sent to Kafka</description><displayName>Partition Strategy</displayName><dynamic>false</dynamic><name>Partition Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Topic Name</key><value><description>The Kafka Topic of interest</description><displayName>Topic Name</displayName><dynamic>false</dynamic><name>Topic Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Kafka Key</key><value><description>The Key to use for the Message</description><displayName>Kafka Key</displayName><dynamic>false</dynamic><name>Kafka Key</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Delivery Guarantee</key><value><allowableValues><description>FlowFile will be routed to success after successfully writing the content to a Kafka node, without waiting for a response. This provides the best performance but may result in data loss.</description><displayName>Best Effort</displayName><value>0</value></allowableValues><allowableValues><description>FlowFile will be routed to success if the message is received by a single Kafka node, whether or not it is replicated. This is faster than &lt;Guarantee Replicated Delivery&gt; but can result in data loss if a Kafka node crashes</description><displayName>Guarantee Single Node Delivery</displayName><value>1</value></allowableValues><allowableValues><description>FlowFile will be routed to failure unless the message is replicated to the appropriate number of Kafka Nodes according to the Topic configuration</description><displayName>Guarantee Replicated Delivery</displayName><value>all</value></allowableValues><defaultValue>0</defaultValue><description>Specifies the requirement for guaranteeing that a message is sent to Kafka</description><displayName>Delivery Guarantee</displayName><dynamic>false</dynamic><name>Delivery Guarantee</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Buffer Size</key><value><defaultValue>5 MB</defaultValue><description>The maximum amount of data to buffer in memory before sending to Kafka</description><displayName>Max Buffer Size</displayName><dynamic>false</dynamic><name>Max Buffer Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Queue Buffering Max Time</key><value><defaultValue>5 secs</defaultValue><description>Maximum time to buffer data before sending to Kafka. For example a setting of 100 ms will try to batch together 100 milliseconds' worth of messages to send at once. This will improve throughput but adds message delivery latency due to the buffering.</description><displayName>Queue Buffering Max Time</displayName><dynamic>false</dynamic><name>Queue Buffering Max Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Communications Timeout</key><value><defaultValue>30 secs</defaultValue><description>The amount of time to wait for a response from Kafka before determining that there is a communications error</description><displayName>Communications Timeout</displayName><dynamic>false</dynamic><name>Communications Timeout</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Known Brokers</key><value><description>A comma-separated list of known Kafka Brokers in the format &lt;host&gt;:&lt;port&gt;</description><displayName>Known Brokers</displayName><dynamic>false</dynamic><name>Known Brokers</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Async Batch Size</key><value><defaultValue>200</defaultValue><description>The number of messages to send in one batch. The producer will wait until either this number of messages are ready to send or &quot;Queue Buffering Max Time&quot; is reached. NOTE: This property will be ignored unless the 'Message Delimiter' property is specified.</description><displayName>Batch Size</displayName><dynamic>false</dynamic><name>Async Batch Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Partition</key></entry><entry><key>Max Record Size</key><value>1 MB</value></entry><entry><key>Client Name</key><value>truck_events_client</value></entry><entry><key>Compression Codec</key><value>none</value></entry><entry><key>Message Delimiter</key><value>
</value></entry><entry><key>Partition Strategy</key><value>Round Robin</value></entry><entry><key>Topic Name</key><value>truck_events2</value></entry><entry><key>Kafka Key</key></entry><entry><key>Delivery Guarantee</key><value>0</value></entry><entry><key>Max Buffer Size</key><value>5 MB</value></entry><entry><key>Queue Buffering Max Time</key><value>5 secs</value></entry><entry><key>Communications Timeout</key><value>30 secs</value></entry><entry><key>Known Brokers</key><value>sandbox.hortonworks.com:6667</value></entry><entry><key>Async Batch Size</key><value>16384</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>PutKafka</name><relationships><autoTerminate>true</autoTerminate><description>Any FlowFile that cannot be sent to Kafka will be routed to this Relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Any FlowFile that is successfully sent to Kafka will be routed to this Relationship</description><name>success</name></relationships><state>DISABLED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.kafka.PutKafka</type></processors><processors><id>de1b9195-a809-4aef-abc2-862de896d217</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><position><x>1062.0165732466808</x><y>1.5185724757610046</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Content Buffer Size</key><value><defaultValue>1 MB</defaultValue><description>Specifies the maximum amount of data to buffer in order to apply the regular expressions. If the size of the FlowFile exceeds this value, any amount of this value will be ignored</description><displayName>Content Buffer Size</displayName><dynamic>false</dynamic><name>Content Buffer Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Match Requirement</key><value><allowableValues><displayName>content must match exactly</displayName><value>content must match exactly</value></allowableValues><allowableValues><displayName>content must contain match</displayName><value>content must contain match</value></allowableValues><defaultValue>content must match exactly</defaultValue><description>Specifies whether the entire content of the file must match the regular expression exactly, or if any part of the file (up to Content Buffer Size) can contain the regular expression in order to be considered a match</description><displayName>Match Requirement</displayName><dynamic>false</dynamic><name>Match Requirement</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Character Set</key><value><defaultValue>UTF-8</defaultValue><description>The Character Set in which the file is encoded</description><displayName>Character Set</displayName><dynamic>false</dynamic><name>Character Set</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>search_for_truck_event_data</key><value><description></description><displayName>search_for_truck_event_data</displayName><dynamic>true</dynamic><name>search_for_truck_event_data</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Content Buffer Size</key><value>1 MB</value></entry><entry><key>Match Requirement</key><value>content must contain match</value></entry><entry><key>Character Set</key><value>UTF-8</value></entry><entry><key>search_for_truck_event_data</key><value>(Normal)|(Overspeed)|(Lane Departure)|(Unsafe tail distance)|(Unsafe following distance)</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>RouteOnContent</name><relationships><autoTerminate>false</autoTerminate><description></description><name>search_for_truck_event_data</name></relationships><relationships><autoTerminate>false</autoTerminate><description>FlowFiles that do not match any of the user-supplied regular expressions will be routed to this relationship</description><name>unmatched</name></relationships><state>STOPPED</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.RouteOnContent</type></processors><processors><id>ee4e7849-a123-4958-a297-6062b9818978</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><position><x>523.7233585794669</x><y>413.37493843811205</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Delete Attributes Expression</key><value><description>Regular expression for attributes to be deleted from flowfiles.</description><displayName>Delete Attributes Expression</displayName><dynamic>false</dynamic><name>Delete Attributes Expression</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Delete Attributes Expression</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>UpdateAttribute</name><relationships><autoTerminate>false</autoTerminate><description>All FlowFiles are routed to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.attributes.UpdateAttribute</type></processors><processors><id>dacc95ee-23f0-4c5e-ac74-4232c8ebde42</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><position><x>528.4543819163622</x><y>237.31030775351226</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Remove Trailing Newlines</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>true</defaultValue><description>Whether to remove newlines at the end of each split file. This should be false if you intend to merge the split files later. If this is set to 'true' and a FlowFile is generated that contains only 'empty lines' (i.e., consists only of &#xD; and 
 characters), the FlowFile will not be emitted. Note, however, that if the Header Line Count is greater than 0, the resultant FlowFile will never be empty as it will consist of the header lines, so a FlowFile may be emitted that contians only the header lines.</description><displayName>Remove Trailing Newlines</displayName><dynamic>false</dynamic><name>Remove Trailing Newlines</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Header Line Count</key><value><defaultValue>0</defaultValue><description>The number of lines that should be considered part of the header; the header lines will be duplicated to all split files</description><displayName>Header Line Count</displayName><dynamic>false</dynamic><name>Header Line Count</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Line Split Count</key><value><description>The number of lines that will be added to each split file (excluding the header, if the Header Line Count property is greater than 0).</description><displayName>Line Split Count</displayName><dynamic>false</dynamic><name>Line Split Count</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Remove Trailing Newlines</key><value>false</value></entry><entry><key>Header Line Count</key><value>0</value></entry><entry><key>Line Split Count</key><value>1</value></entry></properties><runDurationMillis>25</runDurationMillis><schedulingPeriod>1 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>SplitText</name><relationships><autoTerminate>true</autoTerminate><description>If a file cannot be split for some reason, the original file will be routed to this destination and nothing will be routed elsewhere</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>The original input file will be routed to this destination when it has been successfully split into 1 or more files</description><name>original</name></relationships><relationships><autoTerminate>false</autoTerminate><description>The split files will be routed to this destination when an input file is successfully split into 1 or more split files</description><name>splits</name></relationships><state>STOPPED</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.SplitText</type></processors><processors><id>e9dd9706-19f8-4e43-8c0b-5961ef72626f</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><position><x>1064.4740331067728</x><y>236.44432244968925</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Keep Path</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>If using the Zip or Tar Merge Format, specifies whether or not the FlowFiles' paths should be included in their entry names; if using other merge strategy, this value is ignored</description><displayName>Keep Path</displayName><dynamic>false</dynamic><name>Keep Path</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum Group Size</key><value><description>The maximum size for the bundle. If not specified, there is no maximum.</description><displayName>Maximum Group Size</displayName><dynamic>false</dynamic><name>Maximum Group Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Merge Strategy</key><value><allowableValues><description>Generates 'bins' of FlowFiles and fills each bin as full as possible. FlowFiles are placed into a bin based on their size and optionally their attributes (if the &lt;Correlation Attribute&gt; property is set)</description><displayName>Bin-Packing Algorithm</displayName><value>Bin-Packing Algorithm</value></allowableValues><allowableValues><description>Combines fragments that are associated by attributes back into a single cohesive FlowFile. If using this strategy, all FlowFiles must have the attributes &lt;fragment.identifier&gt;, &lt;fragment.count&gt;, and &lt;fragment.index&gt; or alternatively (for backward compatibility purposes) &lt;segment.identifier&gt;, &lt;segment.count&gt;, and &lt;segment.index&gt;. All FlowFiles with the same value for &quot;fragment.identifier&quot; will be grouped together. All FlowFiles in this group must have the same value for the &quot;fragment.count&quot; attribute. All FlowFiles in this group must have a unique value for the &quot;fragment.index&quot; attribute between 0 and the value of the &quot;fragment.count&quot; attribute.</description><displayName>Defragment</displayName><value>Defragment</value></allowableValues><defaultValue>Bin-Packing Algorithm</defaultValue><description>Specifies the algorithm used to merge content. The 'Defragment' algorithm combines fragments that are associated by attributes back into a single cohesive FlowFile. The 'Bin-Packing Algorithm' generates a FlowFile populated by arbitrarily chosen FlowFiles</description><displayName>Merge Strategy</displayName><dynamic>false</dynamic><name>Merge Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Attribute Strategy</key><value><allowableValues><displayName>Keep Only Common Attributes</displayName><value>Keep Only Common Attributes</value></allowableValues><allowableValues><displayName>Keep All Unique Attributes</displayName><value>Keep All Unique Attributes</value></allowableValues><defaultValue>Keep Only Common Attributes</defaultValue><description>Determines which FlowFile attributes should be added to the bundle. If 'Keep All Unique Attributes' is selected, any attribute on any FlowFile that gets bundled will be kept unless its value conflicts with the value from another FlowFile. If 'Keep Only Common Attributes' is selected, only the attributes that exist on all FlowFiles in the bundle, with the same value, will be preserved.</description><displayName>Attribute Strategy</displayName><dynamic>false</dynamic><name>Attribute Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Compression Level</key><value><allowableValues><displayName>0</displayName><value>0</value></allowableValues><allowableValues><displayName>1</displayName><value>1</value></allowableValues><allowableValues><displayName>2</displayName><value>2</value></allowableValues><allowableValues><displayName>3</displayName><value>3</value></allowableValues><allowableValues><displayName>4</displayName><value>4</value></allowableValues><allowableValues><displayName>5</displayName><value>5</value></allowableValues><allowableValues><displayName>6</displayName><value>6</value></allowableValues><allowableValues><displayName>7</displayName><value>7</value></allowableValues><allowableValues><displayName>8</displayName><value>8</value></allowableValues><allowableValues><displayName>9</displayName><value>9</value></allowableValues><defaultValue>1</defaultValue><description>Specifies the compression level to use when using the Zip Merge Format; if not using the Zip Merge Format, this value is ignored</description><displayName>Compression Level</displayName><dynamic>false</dynamic><name>Compression Level</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum Number of Entries</key><value><description>The maximum number of files to include in a bundle. If not specified, there is no maximum.</description><displayName>Maximum Number of Entries</displayName><dynamic>false</dynamic><name>Maximum Number of Entries</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Minimum Group Size</key><value><defaultValue>0 B</defaultValue><description>The minimum size of for the bundle</description><displayName>Minimum Group Size</displayName><dynamic>false</dynamic><name>Minimum Group Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum number of Bins</key><value><defaultValue>100</defaultValue><description>Specifies the maximum number of bins that can be held in memory at any one time</description><displayName>Maximum number of Bins</displayName><dynamic>false</dynamic><name>Maximum number of Bins</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Delimiter Strategy</key><value><allowableValues><description>The values of Header, Footer, and Demarcator will be retrieved from the contents of a file</description><displayName>Filename</displayName><value>Filename</value></allowableValues><allowableValues><description>The values of Header, Footer, and Demarcator will be specified as property values</description><displayName>Text</displayName><value>Text</value></allowableValues><defaultValue>Filename</defaultValue><description>Determines if Header, Footer, and Demarcator should point to files containing the respective content, or if the values of the properties should be used as the content.</description><displayName>Delimiter Strategy</displayName><dynamic>false</dynamic><name>Delimiter Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Merge Format</key><value><allowableValues><description>A bin of FlowFiles will be combined into a single TAR file. The FlowFiles' &lt;path&gt; attribute will be used to create a directory in the TAR file if the &lt;Keep Paths&gt; property is set to true; otherwise, all FlowFiles will be added at the root of the TAR file. If a FlowFile has an attribute named &lt;tar.permissions&gt; that is 3 characters, each between 0-7, that attribute will be used as the TAR entry's 'mode'.</description><displayName>TAR</displayName><value>TAR</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single ZIP file. The FlowFiles' &lt;path&gt; attribute will be used to create a directory in the ZIP file if the &lt;Keep Paths&gt; property is set to true; otherwise, all FlowFiles will be added at the root of the ZIP file. The &lt;Compression Level&gt; property indicates the ZIP compression to use.</description><displayName>ZIP</displayName><value>ZIP</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 3 FlowFile Stream</description><displayName>FlowFile Stream, v3</displayName><value>FlowFile Stream, v3</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 2 FlowFile Stream</description><displayName>FlowFile Stream, v2</displayName><value>FlowFile Stream, v2</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 1 FlowFile Package</description><displayName>FlowFile Tar, v1</displayName><value>FlowFile Tar, v1</value></allowableValues><allowableValues><description>The contents of all FlowFiles will be concatenated together into a single FlowFile</description><displayName>Binary Concatenation</displayName><value>Binary Concatenation</value></allowableValues><allowableValues><description>The Avro contents of all FlowFiles will be concatenated together into a single FlowFile</description><displayName>Avro</displayName><value>Avro</value></allowableValues><defaultValue>Binary Concatenation</defaultValue><description>Determines the format that will be used to merge the content.</description><displayName>Merge Format</displayName><dynamic>false</dynamic><name>Merge Format</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Footer File</key><value><description>Filename specifying the footer to use. If not specified, no footer is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Footer</displayName><dynamic>false</dynamic><name>Footer File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Bin Age</key><value><description>The maximum age of a Bin that will trigger a Bin to be complete. Expected format is &lt;duration&gt; &lt;time unit&gt; where &lt;duration&gt; is a positive integer and time unit is one of seconds, minutes, hours</description><displayName>Max Bin Age</displayName><dynamic>false</dynamic><name>Max Bin Age</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Demarcator File</key><value><description>Filename specifying the demarcator to use. If not specified, no demarcator is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Demarcator</displayName><dynamic>false</dynamic><name>Demarcator File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Correlation Attribute Name</key><value><description>If specified, like FlowFiles will be binned together, where 'like FlowFiles' means FlowFiles that have the same value for this Attribute. If not specified, FlowFiles are bundled by the order in which they are pulled from the queue.</description><displayName>Correlation Attribute Name</displayName><dynamic>false</dynamic><name>Correlation Attribute Name</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Header File</key><value><description>Filename specifying the header to use. If not specified, no header is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Header</displayName><dynamic>false</dynamic><name>Header File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Minimum Number of Entries</key><value><defaultValue>1</defaultValue><description>The minimum number of files to include in a bundle</description><displayName>Minimum Number of Entries</displayName><dynamic>false</dynamic><name>Minimum Number of Entries</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Keep Path</key><value>false</value></entry><entry><key>Maximum Group Size</key></entry><entry><key>Merge Strategy</key><value>Bin-Packing Algorithm</value></entry><entry><key>Attribute Strategy</key><value>Keep Only Common Attributes</value></entry><entry><key>Compression Level</key><value>1</value></entry><entry><key>Maximum Number of Entries</key><value>70</value></entry><entry><key>Minimum Group Size</key><value>0 B</value></entry><entry><key>Maximum number of Bins</key><value>100</value></entry><entry><key>Delimiter Strategy</key><value>Filename</value></entry><entry><key>Merge Format</key><value>Binary Concatenation</value></entry><entry><key>Footer File</key></entry><entry><key>Max Bin Age</key></entry><entry><key>Demarcator File</key></entry><entry><key>Correlation Attribute Name</key></entry><entry><key>Header File</key></entry><entry><key>Minimum Number of Entries</key><value>50</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>MergeContent(truck_events)</name><relationships><autoTerminate>true</autoTerminate><description>If the bundle cannot be created, all FlowFiles that would have been used to created the bundle will be transferred to failure</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>The FlowFile containing the merged content</description><name>merged</name></relationships><relationships><autoTerminate>true</autoTerminate><description>The FlowFiles that were used to create the bundle</description><name>original</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.MergeContent</type></processors><processors><id>3a358c2b-5348-4aa3-95e1-3f805e589f4a</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><position><x>1265.8378757499595</x><y>590.4794343006288</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Proxy Host</key><value><description>Proxy host name or IP</description><displayName>Proxy Host</displayName><dynamic>false</dynamic><name>Proxy Host</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Storage Class</key><value><allowableValues><displayName>Standard</displayName><value>Standard</value></allowableValues><allowableValues><displayName>ReducedRedundancy</displayName><value>ReducedRedundancy</value></allowableValues><defaultValue>Standard</defaultValue><description></description><displayName>Storage Class</displayName><dynamic>false</dynamic><name>Storage Class</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>FullControl User List</key><value><defaultValue>${s3.permissions.full.users}</defaultValue><description>A comma-separated list of Amazon User ID's or E-mail addresses that specifies who should have Full Control for an object</description><displayName>FullControl User List</displayName><dynamic>false</dynamic><name>FullControl User List</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Owner</key><value><defaultValue>${s3.owner}</defaultValue><description>The Amazon ID to use for the object's owner</description><displayName>Owner</displayName><dynamic>false</dynamic><name>Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Access Key</key><value><description></description><displayName>Access Key</displayName><dynamic>false</dynamic><name>Access Key</name><required>false</required><sensitive>true</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Multipart Part Size</key><value><defaultValue>5 GB</defaultValue><description>Specifies the part size for use when the PutS3Multipart Upload API is used.
Flow files will be broken into chunks of this size for the upload process, but the last part sent can be smaller since it is not padded.
The valid range is 50MB to 5GB.</description><displayName>Multipart Part Size</displayName><dynamic>false</dynamic><name>Multipart Part Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Endpoint Override URL</key><value><description>Endpoint URL to use instead of the AWS default including scheme, host, port, and path. The AWS libraries select an endpoint URL based on the AWS region, but this property overrides the selected endpoint URL, allowing use with other S3-compatible endpoints.</description><displayName>Endpoint Override URL</displayName><dynamic>false</dynamic><name>Endpoint Override URL</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Multipart Upload Max Age Threshold</key><value><defaultValue>7 days</defaultValue><description>Specifies the maximum age for existing multipart uploads in AWS S3.  When the ageoff process occurs, any upload older than this threshold will be aborted.</description><displayName>Multipart Upload Max Age Threshold</displayName><dynamic>false</dynamic><name>Multipart Upload Max Age Threshold</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Object Key</key><value><defaultValue>${filename}</defaultValue><description></description><displayName>Object Key</displayName><dynamic>false</dynamic><name>Object Key</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>AWS Credentials Provider service</key><value><description>The Controller Service that is used to obtain aws credentials provider</description><displayName>AWS Credentials Provider service</displayName><dynamic>false</dynamic><identifiesControllerService>org.apache.nifi.processors.aws.credentials.provider.service.AWSCredentialsProviderService</identifiesControllerService><name>AWS Credentials Provider service</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Multipart Threshold</key><value><defaultValue>5 GB</defaultValue><description>Specifies the file size threshold for switch from the PutS3Object API to the PutS3MultipartUpload API.  Flow files bigger than this limit will be sent using the stateful multipart process.
The valid range is 50MB to 5GB.</description><displayName>Multipart Threshold</displayName><dynamic>false</dynamic><name>Multipart Threshold</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SSL Context Service</key><value><description>Specifies an optional SSL Context Service that, if provided, will be used to create connections</description><displayName>SSL Context Service</displayName><dynamic>false</dynamic><identifiesControllerService>org.apache.nifi.ssl.SSLContextService</identifiesControllerService><name>SSL Context Service</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Bucket</key><value><description></description><displayName>Bucket</displayName><dynamic>false</dynamic><name>Bucket</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Multipart Upload AgeOff Interval</key><value><defaultValue>60 min</defaultValue><description>Specifies the interval at which existing multipart uploads in AWS S3 will be evaluated for ageoff.  When processor is triggered it will initiate the ageoff evaluation if this interval has been exceeded.</description><displayName>Multipart Upload AgeOff Interval</displayName><dynamic>false</dynamic><name>Multipart Upload AgeOff Interval</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Write Permission User List</key><value><defaultValue>${s3.permissions.write.users}</defaultValue><description>A comma-separated list of Amazon User ID's or E-mail addresses that specifies who should have Write Access for an object</description><displayName>Write Permission User List</displayName><dynamic>false</dynamic><name>Write Permission User List</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Communications Timeout</key><value><defaultValue>30 secs</defaultValue><description></description><displayName>Communications Timeout</displayName><dynamic>false</dynamic><name>Communications Timeout</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Secret Key</key><value><description></description><displayName>Secret Key</displayName><dynamic>false</dynamic><name>Secret Key</name><required>false</required><sensitive>true</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Credentials File</key><value><description></description><displayName>Credentials File</displayName><dynamic>false</dynamic><name>Credentials File</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Region</key><value><allowableValues><description>us-gov-west-1</description><displayName>us-gov-west-1</displayName><value>us-gov-west-1</value></allowableValues><allowableValues><description>us-east-1</description><displayName>us-east-1</displayName><value>us-east-1</value></allowableValues><allowableValues><description>us-west-1</description><displayName>us-west-1</displayName><value>us-west-1</value></allowableValues><allowableValues><description>us-west-2</description><displayName>us-west-2</displayName><value>us-west-2</value></allowableValues><allowableValues><description>eu-west-1</description><displayName>eu-west-1</displayName><value>eu-west-1</value></allowableValues><allowableValues><description>eu-central-1</description><displayName>eu-central-1</displayName><value>eu-central-1</value></allowableValues><allowableValues><description>ap-southeast-1</description><displayName>ap-southeast-1</displayName><value>ap-southeast-1</value></allowableValues><allowableValues><description>ap-southeast-2</description><displayName>ap-southeast-2</displayName><value>ap-southeast-2</value></allowableValues><allowableValues><description>ap-northeast-1</description><displayName>ap-northeast-1</displayName><value>ap-northeast-1</value></allowableValues><allowableValues><description>sa-east-1</description><displayName>sa-east-1</displayName><value>sa-east-1</value></allowableValues><allowableValues><description>cn-north-1</description><displayName>cn-north-1</displayName><value>cn-north-1</value></allowableValues><defaultValue>us-west-2</defaultValue><description></description><displayName>Region</displayName><dynamic>false</dynamic><name>Region</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Read Permission User List</key><value><defaultValue>${s3.permissions.read.users}</defaultValue><description>A comma-separated list of Amazon User ID's or E-mail addresses that specifies who should have Read Access for an object</description><displayName>Read Permission User List</displayName><dynamic>false</dynamic><name>Read Permission User List</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Expiration Time Rule</key><value><description></description><displayName>Expiration Time Rule</displayName><dynamic>false</dynamic><name>Expiration Time Rule</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Write ACL User List</key><value><defaultValue>${s3.permissions.writeacl.users}</defaultValue><description>A comma-separated list of Amazon User ID's or E-mail addresses that specifies who should have permissions to change the Access Control List for an object</description><displayName>Write ACL User List</displayName><dynamic>false</dynamic><name>Write ACL User List</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Proxy Host Port</key><value><description>Proxy host port</description><displayName>Proxy Host Port</displayName><dynamic>false</dynamic><name>Proxy Host Port</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Read ACL User List</key><value><defaultValue>${s3.permissions.readacl.users}</defaultValue><description>A comma-separated list of Amazon User ID's or E-mail addresses that specifies who should have permissions to read the Access Control List for an object</description><displayName>Read ACL User List</displayName><dynamic>false</dynamic><name>Read ACL User List</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Proxy Host</key></entry><entry><key>Storage Class</key></entry><entry><key>FullControl User List</key></entry><entry><key>Owner</key></entry><entry><key>Access Key</key></entry><entry><key>Multipart Part Size</key></entry><entry><key>Endpoint Override URL</key></entry><entry><key>Multipart Upload Max Age Threshold</key></entry><entry><key>Object Key</key></entry><entry><key>AWS Credentials Provider service</key></entry><entry><key>Multipart Threshold</key></entry><entry><key>SSL Context Service</key></entry><entry><key>Bucket</key><value>groupm</value></entry><entry><key>Multipart Upload AgeOff Interval</key></entry><entry><key>Write Permission User List</key></entry><entry><key>Communications Timeout</key></entry><entry><key>Secret Key</key></entry><entry><key>Credentials File</key></entry><entry><key>Region</key><value>us-east-1</value></entry><entry><key>Read Permission User List</key></entry><entry><key>Expiration Time Rule</key></entry><entry><key>Write ACL User List</key></entry><entry><key>Proxy Host Port</key></entry><entry><key>Read ACL User List</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>PutS3Object</name><relationships><autoTerminate>true</autoTerminate><description>FlowFiles are routed to failure relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>FlowFiles are routed to success relationship</description><name>success</name></relationships><state>DISABLED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.aws.s3.PutS3Object</type></processors><processors><id>72b20cad-d032-4527-9380-b51f906fdeaf</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><position><x>484.91640858080325</x><y>9.874493231883548</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Command</key><value><description>Specifies the command to be executed; if just the name of an executable is provided, it must be in the user's environment PATH.</description><displayName>Command</displayName><dynamic>false</dynamic><name>Command</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Redirect Error Stream</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>If true will redirect any error stream output of the process to the output stream. This is particularly helpful for processes which write extensively to the error stream or for troubleshooting.</description><displayName>Redirect Error Stream</displayName><dynamic>false</dynamic><name>Redirect Error Stream</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Argument Delimiter</key><value><defaultValue> </defaultValue><description>Delimiter to use to separate arguments for a command [default: space]. Must be a single character.</description><displayName>Argument Delimiter</displayName><dynamic>false</dynamic><name>Argument Delimiter</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Batch Duration</key><value><description>If the process is expected to be long-running and produce textual output, a batch duration can be specified so that the output will be captured for this amount of time and a FlowFile will then be sent out with the results and a new FlowFile will be started, rather than waiting for the process to finish before sending out the results</description><displayName>Batch Duration</displayName><dynamic>false</dynamic><name>Batch Duration</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Command Arguments</key><value><description>The arguments to supply to the executable delimited by white space. White space can be escaped by enclosing it in double-quotes.</description><displayName>Command Arguments</displayName><dynamic>false</dynamic><name>Command Arguments</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Command</key><value>sh</value></entry><entry><key>Redirect Error Stream</key><value>false</value></entry><entry><key>Argument Delimiter</key><value> </value></entry><entry><key>Batch Duration</key><value>10 sec</value></entry><entry><key>Command Arguments</key><value>/root/iot-truck-streaming/stream-simulator/generate.sh</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>1 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>ExecuteProcess</name><relationships><autoTerminate>false</autoTerminate><description>All created FlowFiles are routed to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.ExecuteProcess</type></processors><processors><id>c593912d-ceeb-4bce-b16c-8d9af0bf9cb3</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><position><x>1617.9568557034</x><y>74.03831309993359</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Group</key><value><description>Sets the group on the output file to the value of this attribute.  You may also use expression language such as ${file.group}.</description><displayName>Group</displayName><dynamic>false</dynamic><name>Group</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Owner</key><value><description>Sets the owner on the output file to the value of this attribute.  You may also use expression language such as ${file.owner}.</description><displayName>Owner</displayName><dynamic>false</dynamic><name>Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Create Missing Directories</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>true</defaultValue><description>If true, then missing destination directories will be created. If false, flowfiles are penalized and sent to failure.</description><displayName>Create Missing Directories</displayName><dynamic>false</dynamic><name>Create Missing Directories</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Permissions</key><value><description>Sets the permissions on the output file to the value of this attribute.  Format must be either UNIX rwxrwxrwx with a - in place of denied permissions (e.g. rw-r--r--) or an octal number (e.g. 644).  You may also use expression language such as ${file.permissions}.</description><displayName>Permissions</displayName><dynamic>false</dynamic><name>Permissions</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Maximum File Count</key><value><description>Specifies the maximum number of files that can exist in the output directory</description><displayName>Maximum File Count</displayName><dynamic>false</dynamic><name>Maximum File Count</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Last Modified Time</key><value><description>Sets the lastModifiedTime on the output file to the value of this attribute.  Format must be yyyy-MM-dd'T'HH:mm:ssZ.  You may also use expression language such as ${file.lastModifiedTime}.</description><displayName>Last Modified Time</displayName><dynamic>false</dynamic><name>Last Modified Time</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Directory</key><value><description>The directory to which files should be written. You may use expression language such as /aa/bb/${path}</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Group</key></entry><entry><key>Owner</key></entry><entry><key>Create Missing Directories</key><value>true</value></entry><entry><key>Permissions</key></entry><entry><key>Maximum File Count</key></entry><entry><key>Last Modified Time</key></entry><entry><key>Directory</key><value>/root/nifi_output/log_data</value></entry><entry><key>Conflict Resolution Strategy</key><value>fail</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>PutFile(logs)</name><relationships><autoTerminate>true</autoTerminate><description>Files that could not be written to the output directory for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to the output directory are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.PutFile</type></processors><processors><id>acca1884-bb32-45c8-a20a-4bba8630250d</id><parentGroupId>0df58d16-7d9b-4aa1-8832-bb0632857214</parentGroupId><position><x>1693.0751954906666</x><y>563.3439123459682</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Permissions umask</key><value><description>A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode</description><displayName>Permissions umask</displayName><dynamic>false</dynamic><name>Permissions umask</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Owner</key><value><description>Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner</description><displayName>Remote Owner</displayName><dynamic>false</dynamic><name>Remote Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Compression codec</key><value><allowableValues><displayName>NONE</displayName><value>NONE</value></allowableValues><allowableValues><displayName>DEFAULT</displayName><value>DEFAULT</value></allowableValues><allowableValues><displayName>BZIP</displayName><value>BZIP</value></allowableValues><allowableValues><displayName>GZIP</displayName><value>GZIP</value></allowableValues><allowableValues><displayName>LZ4</displayName><value>LZ4</value></allowableValues><allowableValues><displayName>SNAPPY</displayName><value>SNAPPY</value></allowableValues><allowableValues><displayName>AUTOMATIC</displayName><value>AUTOMATIC</value></allowableValues><defaultValue>NONE</defaultValue><description></description><displayName>Compression codec</displayName><dynamic>false</dynamic><name>Compression codec</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>IO Buffer Size</key><value><description>Amount of memory to use to buffer file contents during IO. This overrides the Hadoop Configuration</description><displayName>IO Buffer Size</displayName><dynamic>false</dynamic><name>IO Buffer Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Group</key><value><description>Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group</description><displayName>Remote Group</displayName><dynamic>false</dynamic><name>Remote Group</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Block Size</key><value><description>Size of each block as written to HDFS. This overrides the Hadoop Configuration</description><displayName>Block Size</displayName><dynamic>false</dynamic><name>Block Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Replication</key><value><description>Number of times that HDFS will replicate each file. This overrides the Hadoop Configuration</description><displayName>Replication</displayName><dynamic>false</dynamic><name>Replication</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Relogin Period</key><value><defaultValue>4 hours</defaultValue><description>Period of time which should pass before attempting a kerberos relogin</description><displayName>Kerberos Relogin Period</displayName><dynamic>false</dynamic><name>Kerberos Relogin Period</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Directory</key><value><description>The parent HDFS directory to which files should be written</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Permissions umask</key></entry><entry><key>Hadoop Configuration Resources</key><value>/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml</value></entry><entry><key>Remote Owner</key></entry><entry><key>Compression codec</key><value>NONE</value></entry><entry><key>IO Buffer Size</key></entry><entry><key>Remote Group</key></entry><entry><key>Block Size</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Kerberos Principal</key></entry><entry><key>Replication</key></entry><entry><key>Kerberos Relogin Period</key></entry><entry><key>Directory</key><value>/groupm/</value></entry><entry><key>Conflict Resolution Strategy</key><value>replace</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>PutHDFS</name><relationships><autoTerminate>true</autoTerminate><description>Files that could not be written to HDFS for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to HDFS are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.hadoop.PutHDFS</type></processors></snippet><timestamp>02/26/2017 03:50:21 UTC</timestamp></template>